{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPWH7XNO8nZM"
   },
   "source": [
    "# HW 2: Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fncLvGe28nZN"
   },
   "source": [
    "In this homework you will be building several varieties of language models.\n",
    "\n",
    "## Goal\n",
    "\n",
    "We ask that you construct the following models in Torch / NamedTensor:\n",
    "\n",
    "1. A count-based trigram model with linear-interpolation. $$p(y_t | y_{1:t-1}) =  \\alpha_1 p(y_t | y_{t-2}, y_{t-1}) + \\alpha_2 p(y_t | y_{t-1}) + (1 - \\alpha_1 - \\alpha_2) p(y_t) $$\n",
    "2. A neural network language model (consult *A Neural Probabilistic Language Model* http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "3. An LSTM language model (consult *Recurrent Neural Network Regularization*, https://arxiv.org/pdf/1409.2329.pdf) \n",
    "4. Your own extensions to these models.\n",
    "\n",
    "\n",
    "Consult the papers provided for hyperparameters.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxPRHeF08nZO"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This notebook provides a working definition of the setup of the problem itself. You may construct your models inline or use an external setup (preferred) to build your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s6dq9Ut782YG",
    "outputId": "c0b44792-cfeb-43a8-d39e-344266f48b48"
   },
   "outputs": [],
   "source": [
    "#!pip install -q torch torchtext opt_einsum\n",
    "#!pip install -qU git+https://github.com/harvardnlp/namedtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nqdDeot8nZP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "from namedtensor import ntorch, NamedTensor\n",
    "from namedtensor.text import NamedField\n",
    "\n",
    "from load import load_text\n",
    "from models import TrigramModel\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, TEXT = load_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrigramModel(.8, .19, len(TEXT.vocab))\n",
    "model.fit(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('batch', 10), ('seqlen', 32), ('distribution', 10001)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(next(iter(val_iter))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GlHfcng8nZS"
   },
   "source": [
    "The dataset we will use of this problem is known as the Penn Treebank (http://aclweb.org/anthology/J93-2004). It is the most famous dataset in NLP and includes a large set of different types of annotations. We will be using it here in a simple case as just a language modeling dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQFcSB478nZU"
   },
   "source": [
    "To start, `torchtext` requires that we define a mapping from the raw text data to featurized indices. These fields make it easy to map back and forth between readable data and math, which helps for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QE3gF0D8nZU"
   },
   "outputs": [],
   "source": [
    "# Our input $x$\n",
    "TEXT = NamedField(names=(\"seqlen\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk5DN87J8nZW"
   },
   "source": [
    "Next we input our data. Here we will use the first 10k sentences of the standard PTB language modeling split, and tell it the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "nICj0CXD-C2Z",
    "outputId": "ed55f3ca-5d4e-42ec-fe8f-6cee00a516e4"
   },
   "outputs": [],
   "source": [
    "#!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/input.txt\n",
    "#!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/train.5k.txt\n",
    "#!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/train.txt\n",
    "#!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rza-uvgD8nZX"
   },
   "outputs": [],
   "source": [
    "# Data distributed with the assignment\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "    path=\".\", \n",
    "    train=\"train.txt\", validation=\"valid.txt\", test=\"valid.txt\", text_field=TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQYymdMu8nZa"
   },
   "source": [
    "The data format for language modeling is strange. We pretend the entire corpus is one long sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hsGKL1jS8nZb",
    "outputId": "afd31cc0-6746-47d1-baea-180e87562842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 1\n"
     ]
    }
   ],
   "source": [
    "print('len(train)', len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qzWC4vz18nZg"
   },
   "source": [
    "Here's the vocab itself. (This dataset has unk symbols already, but torchtext adds its own.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7d9evM2z8nZh",
    "outputId": "e2a8e7e8-0962-44e8-d90e-70d379d8ca13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 10001\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISe-Tx3g8nZk"
   },
   "source": [
    "When debugging you may want to use a smaller vocab size. This will run much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkwV12tZ8nZl"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    TEXT.build_vocab(train, max_size=1000)\n",
    "    len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WoYwv9rx8nZn"
   },
   "source": [
    "The batching is done in a strange way for language modeling. Each element of the batch consists of `bptt_len` words in order. This makes it easy to run recurrent models like RNNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwqEsvmMGnHT"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.iterator import BPTTIterator\n",
    "from torchtext.data import Batch, Dataset\n",
    "import math\n",
    " \n",
    "\n",
    "class NamedBpttIterator(BPTTIterator):\n",
    "    def __iter__(self):\n",
    "        text = self.dataset[0].text\n",
    "        TEXT = self.dataset.fields['text']\n",
    "        TEXT.eos_token = None\n",
    "        text = text + ([TEXT.pad_token] * int(math.ceil(len(text) / self.batch_size)\n",
    "                                              * self.batch_size - len(text)))\n",
    "        data = TEXT.numericalize(\n",
    "            [text], device=self.device)\n",
    "        data = (data\n",
    "            .stack((\"seqlen\", \"batch\"), \"flat\")\n",
    "            .split(\"flat\", (\"batch\", \"seqlen\"), batch=self.batch_size)\n",
    "            .transpose(\"seqlen\", \"batch\")\n",
    "        )\n",
    "\n",
    "        dataset = Dataset(examples=self.dataset.examples, fields=[\n",
    "            ('text', TEXT), ('target', TEXT)])\n",
    "        while True:\n",
    "            for i in range(0, len(self) * self.bptt_len, self.bptt_len):\n",
    "                self.iterations += 1\n",
    "                seq_len = min(self.bptt_len, len(data) - i - 1)\n",
    "                yield Batch.fromvars(\n",
    "                    dataset, self.batch_size,\n",
    "                    text = data.narrow(\"seqlen\", i, seq_len),\n",
    "                    target = data.narrow(\"seqlen\", i+1, seq_len),\n",
    "                )\n",
    "                         \n",
    "            if not self.repeat:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkF0hMZU8nZo"
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = NamedBpttIterator.splits(\n",
    "    (train, val, test), batch_size=10, device=torch.device(\"cpu\"), bptt_len=32, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpKaUXPo8nZq"
   },
   "source": [
    "Here's what these batches look like. Each is a string of length 32. Sentences are ended with a special `<eos>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "ZTCxJ-Mz8nZr",
    "outputId": "b4553dbf-4d2a-441b-fa1d-cdd22427e803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of text batch [max bptt length, batch size] OrderedDict([('seqlen', 32), ('batch', 10)])\n",
      "Second in batch tensor([  72,    5,   28,  247,   61,   12,  216,    5,    0, 1847,   10,    4,\n",
      "          72,  547,    3, 6506,  163,    7,  105,  479,   38,   31,  295, 4901,\n",
      "          13,    4,   49,    3,    0,    0,   25, 2471])\n",
      "Converted back to string:  shares of its common stock for each of <unk> deposit 's N shares outstanding <eos> liberty national a bank holding company has assets exceeding $ N billion <eos> <unk> <unk> was appointed\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_iter)\n",
    "batch = next(it) \n",
    "print(\"Size of text batch [max bptt length, batch size]\", batch.text.shape)\n",
    "example = batch.text.transpose('batch', 'seqlen')._tensor[1]\n",
    "print(\"Second in batch\", example)\n",
    "print(\"Converted back to string: \", \" \".join([TEXT.vocab.itos[i] for i in example.data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXNZ-aXy8nZu"
   },
   "source": [
    "The next batch will be the continuation of the previous. This is helpful for running recurrent neural networks where you remember the current state when transitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "wYqdPsk-8nZv",
    "outputId": "101e6b7a-9515-4b60-8d77-99a6a2eb41c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted back to string:  president and chief executive officer of this financially troubled department store chain effective nov. N succeeding frank robertson who is retiring early <eos> mr. <unk> was previously president and chief operating officer\n"
     ]
    }
   ],
   "source": [
    "batch = next(it)\n",
    "print(\"Converted back to string: \", \" \".join([TEXT.vocab.itos[i] for i in batch.text.transpose('batch', 'seqlen')._tensor[1].data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phnGMV-G8nZy"
   },
   "source": [
    "The batch object also contains the targets for the given batch in the field `target`. The target is simply the text offset by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   4,\n",
    "         73, 394,  34,   0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KiABGRXoSmea",
    "outputId": "1ad9f7e4-25b3-4701-c408-0fe2e754631f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted back to string:  <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <eos> <unk> <unk> N years old will <unk>\n"
     ]
    }
   ],
   "source": [
    "print(\"Converted back to string: \", \" \".join([TEXT.vocab.itos[i] for i in text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvMmJgTN8nZz"
   },
   "source": [
    "## Assignment\n",
    "\n",
    "Now it is your turn to build the models described at the top of the assignment. \n",
    "\n",
    "Using the data given by this iterator, you should construct 3 different torch models that take in batch.text and produce a distribution over the next word. \n",
    "\n",
    "When a model is trained, use the following test function to produce predictions, and then upload to the kaggle competition: https://www.kaggle.com/c/harvard-cs287-s19-hw2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QzcCGOM8nZz"
   },
   "source": [
    "For the final Kaggle test, we will have you do a next word prediction task. We will provide a 10 word prefix of sentences, and it is your job to predict 10 possible next word candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "enEfiDQ78nZ0",
    "outputId": "f1f24d92-7c48-4492-9d0f-cc156a645687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but while the new york stock exchange did n't fall ___\r\n",
      "some circuit breakers installed after the october N crash failed ___\r\n",
      "the N stock specialist firms on the big board floor ___\r\n",
      "big investment banks refused to step up to the plate ___\r\n",
      "heavy selling of standard & poor 's 500-stock index futures ___\r\n",
      "seven big board stocks ual amr bankamerica walt disney capital ___\r\n",
      "once again the specialists were not able to handle the ___\r\n",
      "<unk> james <unk> chairman of specialists henderson brothers inc. it ___\r\n",
      "when the dollar is in a <unk> even central banks ___\r\n",
      "speculators are calling for a degree of liquidity that is ___\r\n"
     ]
    }
   ],
   "source": [
    "!head input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvQXwMrh8nZ3"
   },
   "source": [
    "As a sample Kaggle submission, let us build a simple unigram model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esywMIzm8nZ5"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count = Counter()\n",
    "for b in iter(train_iter):\n",
    "    count.update(b.text.values.contiguous().view(-1).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({9971: 1,\n",
       "         2: 50770,\n",
       "         9972: 1,\n",
       "         99: 885,\n",
       "         9973: 1,\n",
       "         90: 996,\n",
       "         9975: 1,\n",
       "         2255: 42,\n",
       "         9976: 1,\n",
       "         9977: 1,\n",
       "         313: 331,\n",
       "         9981: 1,\n",
       "         1642: 62,\n",
       "         9982: 1,\n",
       "         5: 24400,\n",
       "         9983: 1,\n",
       "         1064: 102,\n",
       "         9984: 1,\n",
       "         9: 17474,\n",
       "         9985: 1,\n",
       "         714: 151,\n",
       "         9987: 1,\n",
       "         9988: 1,\n",
       "         265: 371,\n",
       "         9989: 1,\n",
       "         821: 132,\n",
       "         9990: 1,\n",
       "         3: 42068,\n",
       "         9992: 1,\n",
       "         9782: 5,\n",
       "         9993: 1,\n",
       "         2003: 49,\n",
       "         9994: 1,\n",
       "         547: 198,\n",
       "         9995: 1,\n",
       "         35: 3245,\n",
       "         9996: 1,\n",
       "         2952: 30,\n",
       "         9997: 1,\n",
       "         18: 4915,\n",
       "         9998: 1,\n",
       "         13: 7541,\n",
       "         9999: 1,\n",
       "         4: 32481,\n",
       "         10000: 1,\n",
       "         49: 1881,\n",
       "         156: 595,\n",
       "         9257: 6,\n",
       "         0: 45020,\n",
       "         121: 740,\n",
       "         1188: 88,\n",
       "         73: 1241,\n",
       "         363: 289,\n",
       "         394: 268,\n",
       "         34: 3270,\n",
       "         2134: 45,\n",
       "         2130: 45,\n",
       "         147: 612,\n",
       "         20: 4833,\n",
       "         7: 21196,\n",
       "         9208: 6,\n",
       "         277: 359,\n",
       "         408: 259,\n",
       "         1566: 66,\n",
       "         7295: 8,\n",
       "         362: 289,\n",
       "         24: 4326,\n",
       "         14: 7337,\n",
       "         354: 295,\n",
       "         142: 635,\n",
       "         7169: 9,\n",
       "         5466: 13,\n",
       "         5371: 13,\n",
       "         311: 333,\n",
       "         3082: 28,\n",
       "         1597: 64,\n",
       "         97: 928,\n",
       "         136: 651,\n",
       "         271: 365,\n",
       "         7683: 8,\n",
       "         6: 23638,\n",
       "         40: 2438,\n",
       "         1182: 89,\n",
       "         80: 1136,\n",
       "         338: 306,\n",
       "         26: 3923,\n",
       "         453: 236,\n",
       "         667: 164,\n",
       "         2478: 37,\n",
       "         4810: 16,\n",
       "         658: 165,\n",
       "         4273: 18,\n",
       "         2171: 44,\n",
       "         956: 114,\n",
       "         550: 197,\n",
       "         25: 4073,\n",
       "         2353: 40,\n",
       "         522: 210,\n",
       "         1470: 70,\n",
       "         393: 269,\n",
       "         37: 2704,\n",
       "         1963: 50,\n",
       "         304: 337,\n",
       "         400: 264,\n",
       "         439: 243,\n",
       "         3685: 22,\n",
       "         1277: 82,\n",
       "         943: 115,\n",
       "         350: 298,\n",
       "         101: 872,\n",
       "         3151: 27,\n",
       "         497: 219,\n",
       "         264: 372,\n",
       "         1401: 74,\n",
       "         3237: 27,\n",
       "         139: 646,\n",
       "         6093: 11,\n",
       "         4960: 15,\n",
       "         4242: 18,\n",
       "         30: 3541,\n",
       "         6037: 11,\n",
       "         180: 506,\n",
       "         31: 3494,\n",
       "         27: 3914,\n",
       "         989: 110,\n",
       "         501: 218,\n",
       "         56: 1731,\n",
       "         242: 400,\n",
       "         761: 142,\n",
       "         275: 360,\n",
       "         1016: 107,\n",
       "         42: 2362,\n",
       "         2787: 32,\n",
       "         212: 444,\n",
       "         36: 2793,\n",
       "         432: 247,\n",
       "         4116: 19,\n",
       "         561: 192,\n",
       "         15: 6112,\n",
       "         1352: 76,\n",
       "         46: 2065,\n",
       "         11: 8931,\n",
       "         3239: 27,\n",
       "         1806: 56,\n",
       "         196: 468,\n",
       "         197: 467,\n",
       "         1245: 85,\n",
       "         44: 2220,\n",
       "         221: 430,\n",
       "         1752: 57,\n",
       "         7427: 8,\n",
       "         215: 442,\n",
       "         4053: 20,\n",
       "         910: 120,\n",
       "         569: 190,\n",
       "         285: 352,\n",
       "         6886: 9,\n",
       "         23: 4585,\n",
       "         1895: 53,\n",
       "         114: 773,\n",
       "         2653: 34,\n",
       "         309: 334,\n",
       "         8069: 7,\n",
       "         1713: 59,\n",
       "         2475: 37,\n",
       "         43: 2308,\n",
       "         5251: 14,\n",
       "         2532: 36,\n",
       "         2807: 32,\n",
       "         465: 228,\n",
       "         53: 1785,\n",
       "         2783: 32,\n",
       "         3005: 29,\n",
       "         509: 215,\n",
       "         467: 227,\n",
       "         16: 6027,\n",
       "         81: 1132,\n",
       "         168: 547,\n",
       "         1029: 106,\n",
       "         2201: 44,\n",
       "         480: 224,\n",
       "         2646: 35,\n",
       "         115: 772,\n",
       "         287: 350,\n",
       "         66: 1288,\n",
       "         9643: 5,\n",
       "         559: 192,\n",
       "         128: 699,\n",
       "         3575: 23,\n",
       "         1899: 53,\n",
       "         4493: 17,\n",
       "         740: 147,\n",
       "         8: 18000,\n",
       "         1410: 73,\n",
       "         28: 3846,\n",
       "         2206: 43,\n",
       "         1800: 56,\n",
       "         2911: 30,\n",
       "         367: 284,\n",
       "         1977: 50,\n",
       "         3179: 27,\n",
       "         47: 2009,\n",
       "         98: 922,\n",
       "         1158: 92,\n",
       "         41: 2379,\n",
       "         2361: 40,\n",
       "         95: 952,\n",
       "         52: 1838,\n",
       "         468: 227,\n",
       "         208: 452,\n",
       "         343: 302,\n",
       "         1119: 95,\n",
       "         1293: 80,\n",
       "         171: 545,\n",
       "         326: 321,\n",
       "         10: 9784,\n",
       "         5161: 14,\n",
       "         1492: 69,\n",
       "         917: 119,\n",
       "         3200: 27,\n",
       "         5967: 11,\n",
       "         8830: 6,\n",
       "         8968: 6,\n",
       "         502: 218,\n",
       "         372: 282,\n",
       "         92: 961,\n",
       "         1142: 93,\n",
       "         1412: 73,\n",
       "         107: 827,\n",
       "         435: 246,\n",
       "         308: 334,\n",
       "         39: 2562,\n",
       "         1263: 83,\n",
       "         719: 150,\n",
       "         2368: 40,\n",
       "         32: 3477,\n",
       "         1367: 76,\n",
       "         58: 1668,\n",
       "         65: 1397,\n",
       "         947: 115,\n",
       "         276: 359,\n",
       "         586: 186,\n",
       "         1922: 52,\n",
       "         885: 123,\n",
       "         17: 5650,\n",
       "         158: 585,\n",
       "         1780: 56,\n",
       "         1443: 71,\n",
       "         2396: 39,\n",
       "         292: 343,\n",
       "         5792: 12,\n",
       "         105: 846,\n",
       "         1305: 80,\n",
       "         417: 253,\n",
       "         84: 1068,\n",
       "         684: 159,\n",
       "         103: 861,\n",
       "         19: 4894,\n",
       "         664: 164,\n",
       "         229: 416,\n",
       "         190: 481,\n",
       "         160: 577,\n",
       "         100: 875,\n",
       "         4665: 16,\n",
       "         1416: 73,\n",
       "         5279: 13,\n",
       "         57: 1695,\n",
       "         3530: 24,\n",
       "         4376: 18,\n",
       "         2376: 39,\n",
       "         250: 394,\n",
       "         2648: 34,\n",
       "         604: 181,\n",
       "         320: 327,\n",
       "         8422: 7,\n",
       "         315: 329,\n",
       "         182: 493,\n",
       "         3061: 28,\n",
       "         4214: 19,\n",
       "         4119: 19,\n",
       "         530: 206,\n",
       "         51: 1850,\n",
       "         370: 283,\n",
       "         64: 1451,\n",
       "         2366: 40,\n",
       "         59: 1667,\n",
       "         968: 113,\n",
       "         646: 168,\n",
       "         1490: 69,\n",
       "         558: 192,\n",
       "         6031: 11,\n",
       "         942: 115,\n",
       "         652: 166,\n",
       "         344: 301,\n",
       "         759: 142,\n",
       "         979: 111,\n",
       "         206: 457,\n",
       "         659: 165,\n",
       "         1102: 97,\n",
       "         6149: 11,\n",
       "         774: 140,\n",
       "         21: 4724,\n",
       "         211: 445,\n",
       "         163: 568,\n",
       "         443: 240,\n",
       "         253: 385,\n",
       "         767: 141,\n",
       "         721: 150,\n",
       "         1648: 62,\n",
       "         2039: 48,\n",
       "         3484: 24,\n",
       "         844: 129,\n",
       "         597: 183,\n",
       "         6761: 9,\n",
       "         5117: 14,\n",
       "         145: 617,\n",
       "         3305: 26,\n",
       "         1048: 104,\n",
       "         134: 652,\n",
       "         3171: 27,\n",
       "         143: 635,\n",
       "         6374: 10,\n",
       "         254: 385,\n",
       "         578: 188,\n",
       "         1452: 71,\n",
       "         12: 8927,\n",
       "         424: 249,\n",
       "         399: 264,\n",
       "         82: 1126,\n",
       "         1846: 54,\n",
       "         267: 369,\n",
       "         1551: 66,\n",
       "         3123: 28,\n",
       "         770: 140,\n",
       "         1936: 51,\n",
       "         2156: 45,\n",
       "         230: 416,\n",
       "         653: 166,\n",
       "         6067: 11,\n",
       "         5405: 13,\n",
       "         802: 135,\n",
       "         381: 275,\n",
       "         3048: 29,\n",
       "         2321: 41,\n",
       "         239: 402,\n",
       "         2167: 44,\n",
       "         626: 173,\n",
       "         38: 2680,\n",
       "         792: 137,\n",
       "         946: 115,\n",
       "         1390: 75,\n",
       "         5523: 13,\n",
       "         2157: 45,\n",
       "         5546: 13,\n",
       "         800: 136,\n",
       "         2215: 43,\n",
       "         133: 665,\n",
       "         6503: 10,\n",
       "         422: 250,\n",
       "         170: 545,\n",
       "         89: 1010,\n",
       "         298: 341,\n",
       "         347: 300,\n",
       "         386: 272,\n",
       "         259: 378,\n",
       "         6662: 10,\n",
       "         7515: 8,\n",
       "         3279: 26,\n",
       "         4465: 17,\n",
       "         7642: 8,\n",
       "         377: 281,\n",
       "         1635: 62,\n",
       "         346: 301,\n",
       "         2036: 48,\n",
       "         2796: 32,\n",
       "         7537: 8,\n",
       "         2930: 30,\n",
       "         5173: 14,\n",
       "         2072: 47,\n",
       "         233: 412,\n",
       "         290: 344,\n",
       "         71: 1246,\n",
       "         207: 453,\n",
       "         445: 240,\n",
       "         291: 344,\n",
       "         526: 207,\n",
       "         549: 197,\n",
       "         4505: 17,\n",
       "         159: 579,\n",
       "         8250: 7,\n",
       "         4197: 19,\n",
       "         677: 160,\n",
       "         1884: 53,\n",
       "         151: 606,\n",
       "         272: 364,\n",
       "         2544: 36,\n",
       "         506: 216,\n",
       "         939: 116,\n",
       "         3910: 21,\n",
       "         585: 186,\n",
       "         257: 383,\n",
       "         1422: 72,\n",
       "         5327: 13,\n",
       "         2354: 40,\n",
       "         380: 278,\n",
       "         1058: 103,\n",
       "         1714: 59,\n",
       "         902: 122,\n",
       "         2026: 48,\n",
       "         1311: 79,\n",
       "         2600: 35,\n",
       "         1929: 51,\n",
       "         1591: 64,\n",
       "         1166: 92,\n",
       "         29: 3632,\n",
       "         1284: 81,\n",
       "         651: 167,\n",
       "         6081: 11,\n",
       "         673: 161,\n",
       "         352: 296,\n",
       "         403: 262,\n",
       "         4957: 15,\n",
       "         1024: 107,\n",
       "         261: 376,\n",
       "         83: 1069,\n",
       "         2297: 41,\n",
       "         1840: 54,\n",
       "         96: 939,\n",
       "         125: 719,\n",
       "         316: 328,\n",
       "         438: 243,\n",
       "         300: 339,\n",
       "         3962: 20,\n",
       "         2618: 35,\n",
       "         685: 159,\n",
       "         735: 148,\n",
       "         1474: 70,\n",
       "         415: 254,\n",
       "         130: 688,\n",
       "         1988: 49,\n",
       "         54: 1774,\n",
       "         6191: 11,\n",
       "         1355: 76,\n",
       "         1424: 72,\n",
       "         2119: 45,\n",
       "         3211: 27,\n",
       "         247: 395,\n",
       "         339: 305,\n",
       "         945: 115,\n",
       "         1383: 75,\n",
       "         7664: 8,\n",
       "         552: 196,\n",
       "         91: 981,\n",
       "         62: 1566,\n",
       "         1637: 62,\n",
       "         165: 551,\n",
       "         783: 138,\n",
       "         1275: 82,\n",
       "         654: 166,\n",
       "         7128: 9,\n",
       "         2245: 43,\n",
       "         55: 1764,\n",
       "         262: 376,\n",
       "         2581: 36,\n",
       "         1619: 63,\n",
       "         9686: 5,\n",
       "         5591: 12,\n",
       "         176: 525,\n",
       "         33: 3388,\n",
       "         2658: 34,\n",
       "         3120: 28,\n",
       "         293: 342,\n",
       "         1494: 69,\n",
       "         5534: 13,\n",
       "         5395: 13,\n",
       "         1736: 58,\n",
       "         6350: 10,\n",
       "         2240: 43,\n",
       "         213: 444,\n",
       "         1878: 53,\n",
       "         5043: 15,\n",
       "         9636: 5,\n",
       "         1489: 69,\n",
       "         447: 240,\n",
       "         166: 551,\n",
       "         302: 339,\n",
       "         6522: 10,\n",
       "         5123: 14,\n",
       "         2126: 45,\n",
       "         8780: 6,\n",
       "         1403: 74,\n",
       "         2296: 41,\n",
       "         2840: 31,\n",
       "         124: 720,\n",
       "         3968: 20,\n",
       "         4669: 16,\n",
       "         6587: 10,\n",
       "         566: 191,\n",
       "         1085: 99,\n",
       "         958: 114,\n",
       "         303: 338,\n",
       "         1379: 75,\n",
       "         3092: 28,\n",
       "         8114: 7,\n",
       "         2051: 47,\n",
       "         9463: 6,\n",
       "         1776: 57,\n",
       "         74: 1227,\n",
       "         1871: 54,\n",
       "         60: 1617,\n",
       "         8930: 6,\n",
       "         512: 213,\n",
       "         1436: 72,\n",
       "         525: 208,\n",
       "         2808: 32,\n",
       "         9232: 6,\n",
       "         4226: 18,\n",
       "         77: 1159,\n",
       "         1760: 57,\n",
       "         251: 391,\n",
       "         1860: 54,\n",
       "         2739: 33,\n",
       "         155: 601,\n",
       "         1356: 76,\n",
       "         4362: 18,\n",
       "         875: 124,\n",
       "         572: 189,\n",
       "         9674: 5,\n",
       "         252: 386,\n",
       "         340: 304,\n",
       "         452: 236,\n",
       "         2511: 37,\n",
       "         3821: 21,\n",
       "         2041: 48,\n",
       "         786: 138,\n",
       "         3022: 29,\n",
       "         1174: 91,\n",
       "         1682: 60,\n",
       "         1206: 87,\n",
       "         829: 131,\n",
       "         708: 154,\n",
       "         7071: 9,\n",
       "         3261: 26,\n",
       "         236: 409,\n",
       "         1766: 57,\n",
       "         4894: 15,\n",
       "         4392: 18,\n",
       "         798: 136,\n",
       "         590: 185,\n",
       "         872: 125,\n",
       "         7935: 7,\n",
       "         2719: 33,\n",
       "         7390: 8,\n",
       "         9030: 6,\n",
       "         2657: 34,\n",
       "         491: 221,\n",
       "         936: 116,\n",
       "         3923: 20,\n",
       "         219: 431,\n",
       "         329: 318,\n",
       "         334: 313,\n",
       "         3014: 29,\n",
       "         1781: 56,\n",
       "         449: 238,\n",
       "         2887: 31,\n",
       "         799: 136,\n",
       "         1400: 74,\n",
       "         587: 186,\n",
       "         5352: 13,\n",
       "         2662: 34,\n",
       "         6619: 10,\n",
       "         1891: 53,\n",
       "         3021: 29,\n",
       "         1223: 86,\n",
       "         2091: 46,\n",
       "         111: 790,\n",
       "         894: 122,\n",
       "         2723: 33,\n",
       "         4174: 19,\n",
       "         3702: 22,\n",
       "         6387: 10,\n",
       "         1467: 70,\n",
       "         243: 399,\n",
       "         454: 236,\n",
       "         666: 164,\n",
       "         68: 1272,\n",
       "         2738: 33,\n",
       "         2709: 33,\n",
       "         5597: 12,\n",
       "         177: 525,\n",
       "         222: 426,\n",
       "         535: 204,\n",
       "         1758: 57,\n",
       "         928: 118,\n",
       "         3731: 22,\n",
       "         2712: 33,\n",
       "         1360: 76,\n",
       "         194: 475,\n",
       "         609: 179,\n",
       "         2519: 36,\n",
       "         2277: 42,\n",
       "         1634: 62,\n",
       "         1693: 60,\n",
       "         3567: 23,\n",
       "         524: 209,\n",
       "         5029: 15,\n",
       "         392: 269,\n",
       "         1250: 84,\n",
       "         1202: 88,\n",
       "         132: 679,\n",
       "         1252: 84,\n",
       "         173: 532,\n",
       "         224: 422,\n",
       "         5228: 14,\n",
       "         7609: 8,\n",
       "         4097: 19,\n",
       "         85: 1060,\n",
       "         237: 409,\n",
       "         3543: 24,\n",
       "         3221: 27,\n",
       "         7193: 9,\n",
       "         9626: 5,\n",
       "         2397: 39,\n",
       "         703: 154,\n",
       "         162: 569,\n",
       "         294: 342,\n",
       "         238: 406,\n",
       "         724: 150,\n",
       "         2852: 31,\n",
       "         6914: 9,\n",
       "         3654: 23,\n",
       "         375: 281,\n",
       "         164: 553,\n",
       "         2845: 31,\n",
       "         431: 247,\n",
       "         328: 319,\n",
       "         476: 225,\n",
       "         78: 1159,\n",
       "         919: 119,\n",
       "         2289: 41,\n",
       "         6192: 11,\n",
       "         818: 133,\n",
       "         1423: 72,\n",
       "         570: 190,\n",
       "         6140: 11,\n",
       "         1050: 103,\n",
       "         341: 303,\n",
       "         1532: 67,\n",
       "         3823: 21,\n",
       "         135: 651,\n",
       "         745: 145,\n",
       "         273: 363,\n",
       "         172: 533,\n",
       "         8211: 7,\n",
       "         336: 310,\n",
       "         1191: 88,\n",
       "         398: 265,\n",
       "         86: 1031,\n",
       "         8025: 7,\n",
       "         87: 1028,\n",
       "         918: 119,\n",
       "         2438: 38,\n",
       "         4321: 18,\n",
       "         949: 115,\n",
       "         1553: 66,\n",
       "         2177: 44,\n",
       "         1608: 63,\n",
       "         191: 480,\n",
       "         596: 183,\n",
       "         826: 132,\n",
       "         2458: 38,\n",
       "         1309: 80,\n",
       "         342: 303,\n",
       "         3973: 20,\n",
       "         8412: 7,\n",
       "         3280: 26,\n",
       "         990: 110,\n",
       "         1231: 86,\n",
       "         5541: 13,\n",
       "         450: 237,\n",
       "         1123: 95,\n",
       "         188: 482,\n",
       "         332: 315,\n",
       "         6798: 9,\n",
       "         4798: 16,\n",
       "         1363: 76,\n",
       "         909: 121,\n",
       "         671: 162,\n",
       "         2007: 49,\n",
       "         823: 132,\n",
       "         5961: 11,\n",
       "         924: 118,\n",
       "         205: 457,\n",
       "         1948: 51,\n",
       "         4923: 15,\n",
       "         528: 207,\n",
       "         382: 273,\n",
       "         7791: 8,\n",
       "         2246: 43,\n",
       "         2170: 44,\n",
       "         48: 2005,\n",
       "         1120: 95,\n",
       "         698: 156,\n",
       "         324: 324,\n",
       "         7629: 8,\n",
       "         727: 149,\n",
       "         2938: 30,\n",
       "         1369: 76,\n",
       "         244: 397,\n",
       "         1705: 59,\n",
       "         705: 154,\n",
       "         337: 309,\n",
       "         102: 870,\n",
       "         1726: 59,\n",
       "         94: 954,\n",
       "         555: 194,\n",
       "         3537: 24,\n",
       "         119: 747,\n",
       "         307: 335,\n",
       "         5669: 12,\n",
       "         4784: 16,\n",
       "         967: 113,\n",
       "         1519: 68,\n",
       "         7009: 9,\n",
       "         2016: 49,\n",
       "         282: 357,\n",
       "         614: 177,\n",
       "         1224: 86,\n",
       "         1184: 89,\n",
       "         961: 113,\n",
       "         472: 226,\n",
       "         120: 747,\n",
       "         199: 463,\n",
       "         8106: 7,\n",
       "         486: 222,\n",
       "         270: 366,\n",
       "         2778: 32,\n",
       "         117: 761,\n",
       "         9274: 6,\n",
       "         5208: 14,\n",
       "         268: 368,\n",
       "         6826: 9,\n",
       "         295: 341,\n",
       "         870: 125,\n",
       "         45: 2092,\n",
       "         1570: 65,\n",
       "         2153: 45,\n",
       "         631: 172,\n",
       "         426: 248,\n",
       "         67: 1281,\n",
       "         1531: 67,\n",
       "         773: 140,\n",
       "         1462: 71,\n",
       "         396: 267,\n",
       "         9176: 6,\n",
       "         944: 115,\n",
       "         2771: 32,\n",
       "         1992: 49,\n",
       "         4770: 16,\n",
       "         7397: 8,\n",
       "         387: 272,\n",
       "         79: 1137,\n",
       "         144: 627,\n",
       "         715: 150,\n",
       "         489: 221,\n",
       "         4407: 18,\n",
       "         201: 462,\n",
       "         1455: 71,\n",
       "         6011: 11,\n",
       "         1409: 74,\n",
       "         246: 396,\n",
       "         333: 314,\n",
       "         9803: 5,\n",
       "         494: 220,\n",
       "         1886: 53,\n",
       "         880: 124,\n",
       "         1141: 93,\n",
       "         1083: 99,\n",
       "         9722: 5,\n",
       "         1428: 72,\n",
       "         7382: 8,\n",
       "         126: 714,\n",
       "         1061: 102,\n",
       "         2534: 36,\n",
       "         2747: 33,\n",
       "         266: 370,\n",
       "         1386: 75,\n",
       "         789: 137,\n",
       "         5075: 14,\n",
       "         466: 227,\n",
       "         2236: 43,\n",
       "         1969: 50,\n",
       "         3523: 24,\n",
       "         4888: 15,\n",
       "         2500: 37,\n",
       "         3783: 21,\n",
       "         923: 118,\n",
       "         203: 459,\n",
       "         1035: 105,\n",
       "         2716: 33,\n",
       "         5308: 13,\n",
       "         3358: 25,\n",
       "         2825: 32,\n",
       "         2298: 41,\n",
       "         5702: 12,\n",
       "         8172: 7,\n",
       "         3976: 20,\n",
       "         3600: 23,\n",
       "         8068: 7,\n",
       "         1192: 88,\n",
       "         1447: 71,\n",
       "         218: 437,\n",
       "         1235: 85,\n",
       "         6030: 11,\n",
       "         674: 161,\n",
       "         2391: 39,\n",
       "         4168: 19,\n",
       "         3089: 28,\n",
       "         744: 145,\n",
       "         1246: 85,\n",
       "         2546: 36,\n",
       "         921: 119,\n",
       "         241: 400,\n",
       "         771: 140,\n",
       "         636: 171,\n",
       "         915: 120,\n",
       "         1830: 55,\n",
       "         500: 219,\n",
       "         692: 158,\n",
       "         75: 1189,\n",
       "         416: 253,\n",
       "         7430: 8,\n",
       "         184: 492,\n",
       "         591: 185,\n",
       "         679: 159,\n",
       "         469: 226,\n",
       "         110: 791,\n",
       "         2755: 33,\n",
       "         628: 173,\n",
       "         556: 194,\n",
       "         1325: 78,\n",
       "         2113: 46,\n",
       "         22: 4627,\n",
       "         63: 1511,\n",
       "         1074: 101,\n",
       "         479: 224,\n",
       "         406: 260,\n",
       "         2143: 45,\n",
       "         1389: 75,\n",
       "         725: 149,\n",
       "         1890: 53,\n",
       "         567: 191,\n",
       "         1698: 59,\n",
       "         4405: 18,\n",
       "         6723: 9,\n",
       "         198: 467,\n",
       "         61: 1611,\n",
       "         1579: 65,\n",
       "         1144: 93,\n",
       "         314: 330,\n",
       "         369: 283,\n",
       "         788: 137,\n",
       "         227: 419,\n",
       "         1543: 66,\n",
       "         223: 424,\n",
       "         7121: 9,\n",
       "         137: 647,\n",
       "         8786: 6,\n",
       "         1099: 98,\n",
       "         1812: 55,\n",
       "         3490: 24,\n",
       "         3423: 25,\n",
       "         777: 139,\n",
       "         8231: 7,\n",
       "         108: 826,\n",
       "         1300: 80,\n",
       "         154: 602,\n",
       "         4373: 18,\n",
       "         70: 1255,\n",
       "         305: 335,\n",
       "         169: 546,\n",
       "         1573: 65,\n",
       "         1475: 70,\n",
       "         5960: 11,\n",
       "         418: 252,\n",
       "         2229: 43,\n",
       "         1413: 73,\n",
       "         4110: 19,\n",
       "         4759: 16,\n",
       "         109: 794,\n",
       "         368: 284,\n",
       "         187: 484,\n",
       "         2303: 41,\n",
       "         1950: 51,\n",
       "         318: 327,\n",
       "         746: 145,\n",
       "         5494: 13,\n",
       "         129: 691,\n",
       "         4142: 19,\n",
       "         2082: 46,\n",
       "         331: 316,\n",
       "         322: 327,\n",
       "         2833: 31,\n",
       "         186: 489,\n",
       "         4525: 17,\n",
       "         1320: 79,\n",
       "         696: 156,\n",
       "         2217: 43,\n",
       "         2093: 46,\n",
       "         2841: 31,\n",
       "         557: 193,\n",
       "         5733: 12,\n",
       "         116: 767,\n",
       "         1747: 58,\n",
       "         1610: 63,\n",
       "         2122: 45,\n",
       "         805: 135,\n",
       "         3495: 24,\n",
       "         542: 201,\n",
       "         3893: 21,\n",
       "         1448: 71,\n",
       "         1930: 51,\n",
       "         1370: 75,\n",
       "         959: 114,\n",
       "         1578: 65,\n",
       "         1951: 51,\n",
       "         1018: 107,\n",
       "         1262: 84,\n",
       "         204: 459,\n",
       "         6851: 9,\n",
       "         464: 228,\n",
       "         9660: 5,\n",
       "         5162: 14,\n",
       "         756: 142,\n",
       "         365: 287,\n",
       "         131: 682,\n",
       "         1087: 99,\n",
       "         2453: 38,\n",
       "         7391: 8,\n",
       "         850: 128,\n",
       "         2382: 39,\n",
       "         817: 133,\n",
       "         5672: 12,\n",
       "         1759: 57,\n",
       "         683: 159,\n",
       "         811: 134,\n",
       "         5334: 13,\n",
       "         1082: 99,\n",
       "         889: 123,\n",
       "         1708: 59,\n",
       "         520: 211,\n",
       "         610: 179,\n",
       "         463: 228,\n",
       "         611: 179,\n",
       "         4153: 19,\n",
       "         2838: 31,\n",
       "         174: 527,\n",
       "         615: 176,\n",
       "         2324: 41,\n",
       "         5454: 13,\n",
       "         994: 110,\n",
       "         153: 605,\n",
       "         1110: 96,\n",
       "         533: 205,\n",
       "         1103: 97,\n",
       "         8286: 7,\n",
       "         1743: 58,\n",
       "         3872: 21,\n",
       "         5598: 12,\n",
       "         720: 150,\n",
       "         335: 312,\n",
       "         1279: 82,\n",
       "         1957: 50,\n",
       "         7293: 8,\n",
       "         4342: 18,\n",
       "         538: 203,\n",
       "         1477: 70,\n",
       "         1848: 54,\n",
       "         1629: 63,\n",
       "         104: 847,\n",
       "         3721: 22,\n",
       "         508: 215,\n",
       "         737: 147,\n",
       "         8793: 6,\n",
       "         4731: 16,\n",
       "         6547: 10,\n",
       "         405: 261,\n",
       "         801: 136,\n",
       "         3223: 27,\n",
       "         6683: 10,\n",
       "         167: 550,\n",
       "         4893: 15,\n",
       "         2806: 32,\n",
       "         5240: 14,\n",
       "         3293: 26,\n",
       "         2322: 41,\n",
       "         442: 240,\n",
       "         969: 112,\n",
       "         931: 117,\n",
       "         1628: 63,\n",
       "         ...})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "count[TEXT.vocab.stoi[\"<eos>\"]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [TEXT.vocab.itos[i] for i, c in count.most_common(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " '<unk>',\n",
       " 'N',\n",
       " 'of',\n",
       " 'to',\n",
       " 'a',\n",
       " 'in',\n",
       " 'and',\n",
       " \"'s\",\n",
       " 'that',\n",
       " 'for',\n",
       " '$',\n",
       " 'is',\n",
       " 'it',\n",
       " 'said',\n",
       " 'on',\n",
       " 'by',\n",
       " 'at',\n",
       " 'as',\n",
       " 'from']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.txt\", \"w\") as fout:\n",
    "    print(\"id,word\", file=fout)\n",
    "    for i, l in enumerate(open(\"input.txt\"), 1):\n",
    "        print(\"%d,%s\"%(i, \" \".join(predictions)), file=fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldI2WGre8naC"
   },
   "source": [
    "The metric we are using is mean average precision of your 20-best list. \n",
    "\n",
    "$$MAP@20 = \\frac{1}{|D|} \\sum_{u=1}^{|D|} \\sum_{k=1}^{20} Precision(u, 1:k)$$\n",
    "\n",
    "Ideally we would use log-likelihood or ppl as discussed in class, but this is the best Kaggle gives us. This takes into account whether you got the right answer and how highly you ranked it. \n",
    "\n",
    "In particular, we ask that you do not game this metric. Please submit *exactly 20* unique predictions for each example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdflwooW8naD"
   },
   "source": [
    "As always you should put up a 5-6 page write-up following the template provided in the repository: https://github.com/harvard-ml-courses/nlp-template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "c57t-VRP8nZ9",
    "outputId": "09c0024d-0313-4e9e-915b-7dea845976f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,word\r\n",
      "1,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "2,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "3,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "4,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "5,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "6,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "7,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "8,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n",
      "9,the <unk> N of to a in and 's that for $ is it said on by at as from\r\n"
     ]
    }
   ],
   "source": [
    "!head sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XV0ZOlv0a4ar"
   },
   "outputs": [],
   "source": [
    "n_words = TEXT.vocab.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0D9uYIvZbIlI"
   },
   "outputs": [],
   "source": [
    "from torch.distributions import dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHzTNaJyb69l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3PJy6fbcZbG"
   },
   "outputs": [],
   "source": [
    "# get word counts in training dataset to determine prior\n",
    "word_counts = torch.zeros([n_words,1],dtype=torch.float32)\n",
    "\n",
    "for batch in train_iter:\n",
    "  word_counts[batch.text.values,0]+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fF8HEJ2GcZyy"
   },
   "outputs": [],
   "source": [
    "marginal  = word_counts.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9Z-omoMdf6F"
   },
   "outputs": [],
   "source": [
    "conditional_count_1 = torch.zeros([n_words,n_words],dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w69tgU2_f8QG"
   },
   "outputs": [],
   "source": [
    "for batch in train_iter:\n",
    "  for c in range(29):\n",
    "    conditional_count_1[batch.text.values[c],batch.text.values[c+1]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slbvAWFxgaJp"
   },
   "outputs": [],
   "source": [
    "# conditional_count_1 0 = y-1, 1 = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5Wo03mkgarc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS 287 T2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
