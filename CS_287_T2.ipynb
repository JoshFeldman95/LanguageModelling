{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPWH7XNO8nZM"
   },
   "source": [
    "# HW 2: Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fncLvGe28nZN"
   },
   "source": [
    "In this homework you will be building several varieties of language models.\n",
    "\n",
    "## Goal\n",
    "\n",
    "We ask that you construct the following models in Torch / NamedTensor:\n",
    "\n",
    "1. A count-based trigram model with linear-interpolation. $$p(y_t | y_{1:t-1}) =  \\alpha_1 p(y_t | y_{t-2}, y_{t-1}) + \\alpha_2 p(y_t | y_{t-1}) + (1 - \\alpha_1 - \\alpha_2) p(y_t) $$\n",
    "2. A neural network language model (consult *A Neural Probabilistic Language Model* http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "3. An LSTM language model (consult *Recurrent Neural Network Regularization*, https://arxiv.org/pdf/1409.2329.pdf) \n",
    "4. Your own extensions to these models.\n",
    "\n",
    "\n",
    "Consult the papers provided for hyperparameters.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxPRHeF08nZO"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This notebook provides a working definition of the setup of the problem itself. You may construct your models inline or use an external setup (preferred) to build your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "s6dq9Ut782YG",
    "outputId": "9cb805d5-8f34-42bf-a136-48a3710083a3"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch torchtext opt_einsum\n",
    "!pip install -qU git+https://github.com/harvardnlp/namedtensor\n",
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nqdDeot8nZP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "from namedtensor import ntorch, NamedTensor\n",
    "from namedtensor.text import NamedField\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from load_data import load_text\n",
    "from models import TrigramModel, LSTM, NeuralNetwork, Transformer\n",
    "from train_models import make_kaggle_submission\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PM3Nuz6uWWTX"
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, TEXT = load_text(\"./data\", device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJjL6-3DXtRg"
   },
   "outputs": [],
   "source": [
    "TEXT.vocab.load_vectors('fasttext.simple.300d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btW4VDANPNKk"
   },
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGSsrwuNaZqi"
   },
   "outputs": [],
   "source": [
    "model = TrigramModel(.8, .16, len(TEXT.vocab))\n",
    "model.fit(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3wcDATWwHLC"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.NLLLoss()\n",
    "running_loss = 0.\n",
    "count = 0\n",
    "for batch in val_iter:\n",
    "    outputs = model.predict(batch.text.cpu()).log()\n",
    "    running_loss += criterion(\n",
    "        outputs.transpose('batch', 'distribution', 'seqlen').values,\n",
    "        batch.target.transpose('batch', 'seqlen').cpu().values).item()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fqBsekRaGrwx",
    "outputId": "1438d52a-4037-4122-daf4-86b4bd2af640"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364.8028120807864"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(running_loss / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4wI8agZPRPQ"
   },
   "source": [
    "### Optimize NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JP2YO2whPW_O"
   },
   "outputs": [],
   "source": [
    "def test_net_hyperparams(hidden, lr, dropout, kernel_size):\n",
    "    \"\"\" Trains and evaluates nn with given params \"\"\"\n",
    "    model = NeuralNetwork(TEXT,\n",
    "                          device='cuda',\n",
    "                          hidden_size=int(hidden),\n",
    "                          kernel_size=int(kernel_size + .5),\n",
    "                          dropout=dropout,\n",
    "                          freeze_embedding=False)\n",
    "    net.fit(train_iter,\n",
    "            val_iter=val_iter,\n",
    "            lr=lr,\n",
    "            batch_size=128,\n",
    "            epochs=50,\n",
    "            early_stopping=True,\n",
    "            verbose=False,)\n",
    "    return -net.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyAakYUVP5s3"
   },
   "outputs": [],
   "source": [
    "net_pbounds = {\n",
    "    'hidden': (32, 512),\n",
    "    'lr': (.0001, .01),\n",
    "    'dropout': (0, .6),\n",
    "    'kernel_size': (2, 5),\n",
    "}\n",
    "\n",
    "net_optimizer = BayesianOptimization(\n",
    "    f=test_net_hyperparams,\n",
    "    pbounds=net_pbounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAmCDU4uQXWK"
   },
   "outputs": [],
   "source": [
    "# tests hyperparameters and finds best configuration\n",
    "net_optimizer.maximize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ki02k2isQfcs"
   },
   "source": [
    "### Optimize LSTM Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QheHKbK4a5RO"
   },
   "outputs": [],
   "source": [
    "def test_lstm_hyperparams(hidden, nlayers, dropout, lr):\n",
    "    lstm = LSTM(TEXT,\n",
    "                device='cuda',\n",
    "                hidden_size=int(hidden),\n",
    "                layers=int(nlayers + .5),\n",
    "                dropout=dropout,\n",
    "                freeze_embedding=False)\n",
    "    lstm.fit(train_iter,\n",
    "             val_iter=val_iter,\n",
    "             lr=lr,\n",
    "             batch_size=128,\n",
    "             epochs=50,\n",
    "             early_stopping=True,\n",
    "             verbose=False)\n",
    "    return -lstm.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTtFLRIrcTMK"
   },
   "outputs": [],
   "source": [
    "lstm_pbounds = {'hidden': (32, 256),\n",
    "                'nlayers': (1, 2),\n",
    "                'dropout': (0, .6),\n",
    "                'lr': (.0001, .01)\n",
    "               }\n",
    "\n",
    "lstm_optimizer = BayesianOptimization(\n",
    "    f=test_lstm_hyperparams,\n",
    "    pbounds=lstm_pbounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJHqLqsddP25"
   },
   "outputs": [],
   "source": [
    "lstm_optimizer.maximize(init_points=3, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wj16-JFDB1jj",
    "outputId": "b32fc37e-8472-445b-977d-5f7b6f987a81"
   },
   "outputs": [],
   "source": [
    "lstm = LSTM(TEXT,\n",
    "            device='cuda',\n",
    "            hidden_size=400,\n",
    "            dropout=.5,\n",
    "            layers=1)\n",
    "lstm.fit(train_iter,\n",
    "        val_iter=val_iter,\n",
    "        lr=.005,\n",
    "        batch_size=128,\n",
    "        epochs=50,\n",
    "        interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvvO9zPX6TDw"
   },
   "outputs": [],
   "source": [
    "lstm.fit(train_iter,\n",
    "        val_iter=test_iter,\n",
    "        lr=.0,\n",
    "        batch_size=128,\n",
    "        epochs=1,\n",
    "        interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dowy7OmeRBEX"
   },
   "source": [
    "### And the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yomunEhRhzx"
   },
   "outputs": [],
   "source": [
    "def test_transformer_hyperparams(num_layers,\n",
    "                                 num_heads,\n",
    "                                 k_depth,\n",
    "                                 v_depth,\n",
    "                                 filt_size):\n",
    "    num_layers = int(num_layers + .5)\n",
    "    num_heads = int(num_layers + .5)\n",
    "    k_depth = int((k_depth // num_heads) * int(num_heads))\n",
    "    v_depth = int((v_depth // num_heads) * int(num_heads))\n",
    "    filt_size = int(filt_size + .5)\n",
    "    tra = Transformer(TEXT,\n",
    "                      device='cuda',\n",
    "                      num_layers=num_layers,\n",
    "                      num_heads=num_heads,\n",
    "                      total_key_depth=k_depth,\n",
    "                      total_value_depth=v_depth,\n",
    "                      filter_size=filt_size,\n",
    "                      freeze_embedding=False)\n",
    "    tra.fit(train_iter,\n",
    "            val_iter=val_iter,\n",
    "            early_stopping=True,\n",
    "            epochs=25,\n",
    "            lr=.001,\n",
    "            verbose=False)\n",
    "    return -tra.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yTYtP6YSBm-"
   },
   "outputs": [],
   "source": [
    "tra_pbounds = {\n",
    "    'num_layers': (3, 8),\n",
    "    'num_heads': (1, 4),\n",
    "    'k_depth': (4, 16),\n",
    "    'v_depth': (4, 16),\n",
    "    'filt_size': (2, 5),\n",
    "}\n",
    "\n",
    "tra_optimizer = BayesianOptimization(\n",
    "    f=test_transformer_hyperparams,\n",
    "    pbounds=tra_pbounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bh_FUugRSVAW"
   },
   "outputs": [],
   "source": [
    "tra_optimizer.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOuEZ1R1-WBA"
   },
   "outputs": [],
   "source": [
    "tra = Transformer(TEXT,\n",
    "                  device='cuda',\n",
    "                  num_layers=3,\n",
    "                  num_heads=1,\n",
    "                  total_key_depth=16,\n",
    "                  total_value_depth=16,\n",
    "                  filter_size=2,\n",
    "                  layer_dropout=.1,\n",
    "                  freeze_embedding=False)\n",
    "tra.fit(train_iter,\n",
    "        val_iter=val_iter,\n",
    "        early_stopping=True,\n",
    "        epochs=50,\n",
    "        lr=.01,\n",
    "        interval=50,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLGKJkRpFdIC"
   },
   "outputs": [],
   "source": [
    "tra.fit(train_iter,\n",
    "        val_iter=test_iter,\n",
    "        early_stopping=True,\n",
    "        epochs=3,\n",
    "        lr=0.00001,\n",
    "        interval=50,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62BbFAiPAFLk"
   },
   "outputs": [],
   "source": [
    "def make_kaggle_submission(model, TEXT, path_to_data = \"./data/\", device = 'cpu'):\n",
    "    kaggle_input = load_kaggle_data(path_to_data+\"/input.txt\", TEXT, device)\n",
    "    pred = model.predict(kaggle_input, predict_last=True)\n",
    "\n",
    "    _, top20 = pred[{'seqlen':-1}].values.topk(20, dim = 1)\n",
    "\n",
    "    with open(path_to_data+\"/sample.txt\", \"w\") as fout:\n",
    "        print(\"id,word\", file=fout)\n",
    "        for i, text in enumerate(top20, 1):\n",
    "            predictions = [TEXT.vocab.itos[word] for word in text]\n",
    "            print(\"%d,%s\"%(i, \" \".join(predictions)), file=fout)\n",
    "\n",
    "def load_kaggle_data(path_to_data, TEXT, device):\n",
    "    with open(path_to_data) as f:\n",
    "        data = f.read()\n",
    "    sentences = [sent for sent in data.split('\\n')[:-1]]\n",
    "    convert_sent_to_int = lambda sent: [TEXT.vocab.stoi[word] for word in sent.split(' ')[:-1]]\n",
    "    sent_list = np.array([convert_sent_to_int(sent) for sent in sentences])\n",
    "    return NamedTensor(torch.from_numpy(sent_list).to(device), names = ('batch','seqlen'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6A-HPdM8Lb2"
   },
   "outputs": [],
   "source": [
    "make_kaggle_submission(lstm, TEXT, path_to_data = \".\", device = 'cuda')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CS 287 T2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
